{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a02879b93c2c>:18: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Abhishek\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "\n",
    "import utils\n",
    "\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "\n",
    "# Step 1: Read in data\n",
    "# using TF Learn's built in function to load MNIST data to the folder data/mnist\n",
    "mnist = input_data.read_data_sets('data/mnist', one_hot=True)\n",
    "X_batch, Y_batch = mnist.train.next_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape = [batch_size,784],name = \"image\")\n",
    "Y = tf.placeholder(tf.int32, shape = [batch_size,10],name = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.get_variable(name = \"weight\",initializer = tf.random_normal_initializer(),shape = (784,10))\n",
    "b = tf.get_variable(name = \"bias\" , initializer = tf.zeros_initializer(),shape = (1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(X,w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits,labels = Y,name = \"loss\")\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = tf.nn.softmax(logits)\n",
    "correct_preds = tf.equal(tf.argmax(preds,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_preds,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss of epoch 0 is 1.6847470554160626\n",
      "Avg loss of epoch 1 is 0.5450759263305397\n",
      "Avg loss of epoch 2 is 0.4347915051978229\n",
      "Avg loss of epoch 3 is 0.38895001908490706\n",
      "Avg loss of epoch 4 is 0.35594914520120285\n",
      "Avg loss of epoch 5 is 0.3371915512464263\n",
      "Avg loss of epoch 6 is 0.32238210265314104\n",
      "Avg loss of epoch 7 is 0.3078718606929679\n",
      "Avg loss of epoch 8 is 0.30224472308631267\n",
      "Avg loss of epoch 9 is 0.2945551887362987\n",
      "Avg loss of epoch 10 is 0.2928874895740778\n",
      "Avg loss of epoch 11 is 0.2847869216284274\n",
      "Avg loss of epoch 12 is 0.2820180500477622\n",
      "Avg loss of epoch 13 is 0.27568291223201996\n",
      "Avg loss of epoch 14 is 0.27888126603581687\n",
      "Avg loss of epoch 15 is 0.2715142985810211\n",
      "Avg loss of epoch 16 is 0.26802424001040714\n",
      "Avg loss of epoch 17 is 0.2705621213102952\n",
      "Avg loss of epoch 18 is 0.2672395071227512\n",
      "Avg loss of epoch 19 is 0.2665510734582281\n",
      "Avg loss of epoch 20 is 0.2645952339980986\n",
      "Avg loss of epoch 21 is 0.2663265085216863\n",
      "Avg loss of epoch 22 is 0.2636517687485768\n",
      "Avg loss of epoch 23 is 0.2618040478590763\n",
      "Avg loss of epoch 24 is 0.26294806778500407\n",
      "Avg loss of epoch 25 is 0.2579208348806088\n",
      "Avg loss of epoch 26 is 0.2557724555541863\n",
      "Avg loss of epoch 27 is 0.2621890510538797\n",
      "Avg loss of epoch 28 is 0.2530694299123504\n",
      "Avg loss of epoch 29 is 0.2578732545524488\n",
      "Accuracy 0.9177\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        total_loss  = 0\n",
    "        \n",
    "        for j in range(n_batches):\n",
    "            \n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            _,loss_batch = sess.run([optimizer,loss],{X:X_batch,Y:Y_batch})\n",
    "            \n",
    "            total_loss += loss_batch\n",
    "            \n",
    "        print(\"Avg loss of epoch {0} is {1}\".format(i,total_loss/n_batches))\n",
    "    \n",
    "    n_batches = int(mnist.test.num_examples/batch_size)\n",
    "    total_correct_preds = 0\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "        accuracy_batch = sess.run(accuracy, {X: X_batch, Y:Y_batch})\n",
    "        total_correct_preds += accuracy_batch\t\n",
    "\n",
    "    print('Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
