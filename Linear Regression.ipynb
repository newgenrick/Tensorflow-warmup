{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "\n",
    "DATA_FILE = 'data/birth_life_2010.txt'\n",
    "\n",
    "# Step 1: read in the data\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "\n",
    "# Step 2: create Dataset and iterator\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "X, Y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = tf.get_variable(\"weight\",initializer=tf.constant(0.0))\n",
    "b = tf.get_variable(\"bias\",initializer = tf.constant(0.0))\n",
    "Y_pred = w*X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.square((Y-Y_pred),name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of epoch 0 is 4894.431352796053\n",
      "loss of epoch 1 is 4800.778501490543\n",
      "loss of epoch 2 is 4710.841622764186\n",
      "loss of epoch 3 is 4622.846031429893\n",
      "loss of epoch 4 is 4536.480333830181\n",
      "loss of epoch 5 is 4451.607728335732\n",
      "loss of epoch 6 is 4368.144851202714\n",
      "loss of epoch 7 is 4286.0319233141445\n",
      "loss of epoch 8 is 4205.221402780633\n",
      "loss of epoch 9 is 4125.673605186061\n",
      "loss of epoch 10 is 4047.3551006116363\n",
      "loss of epoch 11 is 3970.2362741570723\n",
      "loss of epoch 12 is 3894.2920856676606\n",
      "loss of epoch 13 is 3819.5001969186883\n",
      "loss of epoch 14 is 3745.8410535310445\n",
      "loss of epoch 15 is 3673.2979087428043\n",
      "loss of epoch 16 is 3601.856371427837\n",
      "loss of epoch 17 is 3531.5043209678247\n",
      "loss of epoch 18 is 3462.230909166838\n",
      "loss of epoch 19 is 3394.027476742393\n",
      "loss of epoch 20 is 3326.8869672273336\n",
      "loss of epoch 21 is 3260.8035703960218\n",
      "loss of epoch 22 is 3195.773014269377\n",
      "loss of epoch 23 is 3131.79249010588\n",
      "loss of epoch 24 is 3068.860081401624\n",
      "loss of epoch 25 is 3006.9741067183645\n",
      "loss of epoch 26 is 2946.1339247051037\n",
      "loss of epoch 27 is 2886.341948740106\n",
      "loss of epoch 28 is 2827.5976787366367\n",
      "loss of epoch 29 is 2769.9040222569515\n",
      "loss of epoch 30 is 2713.2643529390034\n",
      "loss of epoch 31 is 2657.680320659437\n",
      "loss of epoch 32 is 2603.1561519221254\n",
      "loss of epoch 33 is 2549.6940471849944\n",
      "loss of epoch 34 is 2497.2992770747132\n",
      "loss of epoch 35 is 2445.97596487748\n",
      "loss of epoch 36 is 2395.72849953802\n",
      "loss of epoch 37 is 2346.5603810028024\n",
      "loss of epoch 38 is 2298.476719406014\n",
      "loss of epoch 39 is 2251.4817768699245\n",
      "loss of epoch 40 is 2205.580090830769\n",
      "loss of epoch 41 is 2160.7750433531246\n",
      "loss of epoch 42 is 2117.0697630054074\n",
      "loss of epoch 43 is 2074.467785686112\n",
      "loss of epoch 44 is 2032.9718286336938\n",
      "loss of epoch 45 is 1992.5837120502404\n",
      "loss of epoch 46 is 1953.3044323198496\n",
      "loss of epoch 47 is 1915.1351204790567\n",
      "loss of epoch 48 is 1878.0739169384303\n",
      "loss of epoch 49 is 1842.1190858789842\n",
      "loss of epoch 50 is 1807.268280643011\n",
      "loss of epoch 51 is 1773.5164896964832\n",
      "loss of epoch 52 is 1740.8574699764972\n",
      "loss of epoch 53 is 1709.2833975118047\n",
      "loss of epoch 54 is 1678.7845616761008\n",
      "loss of epoch 55 is 1649.3519161332692\n",
      "loss of epoch 56 is 1620.9711263873075\n",
      "loss of epoch 57 is 1593.6284001642543\n",
      "loss of epoch 58 is 1567.3069475418642\n",
      "loss of epoch 59 is 1541.9876242296193\n",
      "loss of epoch 60 is 1517.652117722599\n",
      "loss of epoch 61 is 1494.278368722113\n",
      "loss of epoch 62 is 1471.8429940305111\n",
      "loss of epoch 63 is 1450.3214640545218\n",
      "loss of epoch 64 is 1429.6880416509193\n",
      "loss of epoch 65 is 1409.9176309935356\n",
      "loss of epoch 66 is 1390.9795943944077\n",
      "loss of epoch 67 is 1372.8469815950646\n",
      "loss of epoch 68 is 1355.4909222078165\n",
      "loss of epoch 69 is 1338.8817348197986\n",
      "loss of epoch 70 is 1322.9901477440212\n",
      "loss of epoch 71 is 1307.786387037133\n",
      "loss of epoch 72 is 1293.2421400094504\n",
      "loss of epoch 73 is 1279.3282706606544\n",
      "loss of epoch 74 is 1266.016088147994\n",
      "loss of epoch 75 is 1253.2787760085967\n",
      "loss of epoch 76 is 1241.0880718739163\n",
      "loss of epoch 77 is 1229.4179499030897\n",
      "loss of epoch 78 is 1218.2436707813488\n",
      "loss of epoch 79 is 1207.540151357239\n",
      "loss of epoch 80 is 1197.283375329906\n",
      "loss of epoch 81 is 1187.4513551757525\n",
      "loss of epoch 82 is 1178.0229947538753\n",
      "loss of epoch 83 is 1168.975166120586\n",
      "loss of epoch 84 is 1160.290746983533\n",
      "loss of epoch 85 is 1151.9506518640017\n",
      "loss of epoch 86 is 1143.9361238868612\n",
      "loss of epoch 87 is 1136.2299292913392\n",
      "loss of epoch 88 is 1128.8167915397078\n",
      "loss of epoch 89 is 1121.681211475224\n",
      "loss of epoch 90 is 1114.808382127787\n",
      "loss of epoch 91 is 1108.1842221580055\n",
      "loss of epoch 92 is 1101.7967779771277\n",
      "loss of epoch 93 is 1095.6327472291887\n",
      "loss of epoch 94 is 1089.6818267879175\n",
      "loss of epoch 95 is 1083.932379993169\n",
      "loss of epoch 96 is 1078.3738579273224\n",
      "loss of epoch 97 is 1072.99665627009\n",
      "loss of epoch 98 is 1067.7917277790998\n",
      "loss of epoch 99 is 1062.750163251632\n",
      "[12.762426, 15.162325]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(100):\n",
    "        sess.run(iterator.initializer)\n",
    "        total_loss = 0\n",
    "        try:\n",
    "            while True:\n",
    "                _,l = sess.run([optimizer,loss])\n",
    "                total_loss +=l\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        print(\"loss of epoch {0} is {1}\".format(i,total_loss/n_samples))\n",
    "        \n",
    "    print(sess.run([w,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
